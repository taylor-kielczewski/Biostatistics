---
title: "Homework 5 - Viviana Romero Alarcon"
format: html
editor: visual
---

**github:**

::: callout-tip
::: {#hello .greeting .message style="color: red;"}
If you are saving your assignments in github, include the link of your repository here
:::
:::

## **1. Correlation - W&S Chapter 16**

Data at <https://whitlockschluter.zoology.ubc.ca/wp-content/data/chapter16/chap16q15LanguageGreyMatter.csv>. Take a look at `cor()` and `cor.test()`. Or get saucy and z-transform your variables! `(x - mean(x))/var(x)`

```{r}
# Load Libraries

library(readr)
library(ggplot2)
# get lizzar data
library(abd)
# check models
library(performance)
library(broom)


```

```{r}
# Load Data

data <- read_csv("https://whitlockschluter.zoology.ubc.ca/wp-content/data/chapter16/chap16q15LanguageGreyMatter.csv")

# Data structure

head(data)

str(data)
```

**1a. Display the association between the two variables in the scatter plot**

```{r}
# scatter plot: association proficiency ~ greymatter

data |>
ggplot(mapping = aes(x = proficiency, y = greymatter)) +
  geom_point( color = "darkblue") +
  geom_smooth(method = "lm", se = FALSE, color = "red") 
```

**1b. Calculate the correlation between the two variables in the scatter plot**

```{r}
 correlation <- cor(y = data$proficiency, x = data$greymatter)
 
 correlation
```

**1c. Test the null hypothesis of zero correlation**

```{r}
testH0 <- cor.test(y = data$proficiency, x = data$greymatter)


testH0
```

::: callout-tip
::: {.greeting .message style="color: red;"}
What are you testing?:

https://www.youtube.com/watch?v=cn4S3QqEBRg
:::
:::

**1d. What are your assumptions in part C?**

I have used pearson's product moment to test the null hypothesis( correlation equal 0). This correlation test assumes variables normally distributed, no outliers, independence observations, and random sample.

**1e. Does the scatter plot support these assumptions? Explain.**

From a scatter plot I can infer the direction of the relationship and how spread are the data. However, I cannot infer if the date are actually normal distributed, or if they are independent observation and random sampled. Indeed, it is not clear if an occurrence is an outlier or not. For that, I must use other statistical analysis to test, normality, outlier, linearity, kurtosis and swekness.

**1f. Do the results demonstrate that second language proficiency affects grey-matter density in the brain? Why or why not?**

Correlation is not causation. Even thought both variables **proficiency** and **grey-matter density** are highly correlated, it does not means grey-matter density is high because of high second language proficiency. I can only infer that the relationship is lineally positive.

## **2. Lizards**

From [Fieberg](https://statistics4ecologistsexercises.netlify.app/linear-regression-review). For this exercise, we will consider the `LizardBite` data set in the `abd` library \[\@abd\]. This data set was collected by \@lappin2005weapon and featured in a problem in \@whitlock2015analysis's popular introductory statistics book. \@lappin2005weapon was interested in whether the bite force (`bite`) of male lizards in the species *Crotaphyutus collaris* was predictive of their territory size (`territory`).

```{r}
# load data (from adb library)
data(LizardBite)

head(LizardBite)

str(LizardBite)
```

**2a. Fit a linear model using R that could be used to predict territory size from a lizard's bite force.**

```{r}
# fit linear model territory ~ bite
LizardBite_lm <- lm(territory ~ bite, data= LizardBite)

summary(LizardBite_lm)
```

**2b. Evaluate the assumptions of the model using graphical methods. Be sure to comment on what you are looking for in each plot (e.g., the assumption you are looking to evaluate and what would constitute an assumption violation).**

::: callout-tip
::: {.greeting .message style="color: red;"}
You can evaluate the model using "check_model()" function or test every assumption using individual functions, by doing this:
:::
:::

```{r}
# Check normality
check_normality(LizardBite_lm)
check_normality(LizardBite_lm) |> plot()





```

```{r}
# Check linearity and Homogeneity of Variance

check_heteroscedasticity(LizardBite_lm)

check_heteroscedasticity(LizardBite_lm) |> plot()
```

```{r}
# Check outliers
check_outliers(LizardBite_lm)

check_outliers(LizardBite_lm) |> plot()
```

```{r}
# Check prediction

check_predictions(LizardBite_lm)

```

::: callout-tip
::: {.greeting .message style="color: red;"}
To explain every plot and result you should read help section from check_model() function

```{r}
# explain Visual check of model assumptions
??performance::check_model	
```
:::
:::

**2c. Interpret the intercept and slope parameters in the context of the problem.**

```{r}
summary.lm(LizardBite_lm)

```

\*\* intercept\*\* = $\beta_0$ = -31.539 The intercept represents the predicted territory size when bite force is zero. However, it lacks of biological meaningful. Instead the **slope** = $\beta_1$ = 11.677 for every 1 unit in bite force, territory size increases by 11.677. it means that males lizards with stronger bite tend to have larger territories.

**2d. Provide a confidence interval for the slope parameter and interpret the confidence interval. Take a look at `confint()`**

```{r}
confint(LizardBite_lm)
```

**2e. Explain what the standard error associated with the slope parameter tells us. Your explanation should include reference to a *sampling distribution*, and you should define what this term means.**

The SE tell us how much $\beta$ could vary if we repeated the sampling from the population. Thus, the larger is SE the higher is the expectation to fluctuate because of sampling variability.

**2f. Create a confidence interval for the mean territory size associated with a bite force of 5 and a prediction interval for a lizard that has a bite force of 5. Explain the difference between the two intervals. When would you prefer the latter type of interval?**

```{r}
# 1. create a seq from the variable ranges

range(LizardBite$bite)

new_data <- data.frame(bite = 5)


```

```{r}
#2. Get confidence intervals
prediction_ci <- predict(LizardBite_lm, newdata = new_data, interval = "confidence") # Confidence Interval

head(prediction_ci)
```

**confidence interval** tell us about where is the true mean value. In this case, we have 95% of confidence that the true value of territory for a bite force of 5 is between 22.51035 31.18403

```{r}
# 3,. Get and prediction intervals
predictions_pi <- predict(LizardBite_lm, newdata = new_data, interval = "prediction") # Prediction Interval

head(predictions_pi)
```

**prediction interval** Considering the natural variability of the data, the model predicts that a lizard with a bite force has a territory of 26.84719 with an uncertainty between 13.05339 40.64099

# 3. A little LaTeX

Using LaTeX, write out the equations underlying simple linear regression.

$$Y_i = 𝛽_0 + 𝛽_1 X_i + 𝜖_i$$

$$ 𝜖_i ∼ 𝓝  (0,𝜎)$$

```         
# show latex code
$$Y_i = 𝛽_0 + 𝛽_1 X_i + 𝜖_i$$
$$ 𝜖_i ∼ 𝓝  (0,𝜎)$$
```

# 4. W&S Chapter 17-30

```{r}
# load Data

cadavers <- read_csv("https://whitlockschluter.zoology.ubc.ca/wp-content/data/chapter17/chap17q30NuclearTeeth.csv")

head(cadavers)
```

**4a. What is the approximate slope of the regression line?**

```{r}
# plot the regression to analyse the slope

ggplot(cadavers, aes(x = dateOfBirth, y = deltaC14)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, color = "green")
```

Without fit a model, I can see from the plot that for each 10 years deltaC14 decreases around 180 units (Check the line between 1970n to 1980). Then, per year, deltaC14 decreases approx 18 units. I can infer that the slope could be approx -18.00

```{r}
# Fit a lineal model

cadavers <- read_csv("https://whitlockschluter.zoology.ubc.ca/wp-content/data/chapter17/chap17q30NuclearTeeth.csv")

cadavers_lm <- lm(deltaC14 ~ dateOfBirth, data = cadavers)

summary(cadavers_lm)
```

If I fit a lineal model, I can check that $\beta_1$ is -16.71 (dateOfBirth)

**4b. Which pair of lines shows the confidence bands? What do these confidence bands tell us?**

From the document plot, **confidence bands** are the narrowest interval around the mean ( black solid line). They show us the confidence interval. We are 95% confident that the actual population mean is in this range.

**4c. Which pair of lines shows the prediction interval? What does this prediction interval tell us?**

From the document plot, the **prediction interval** is wider around the mean ( black solid line). It tells us about the natural data dispersion and shows us that for a point in x, the predicted value in y will be in that range.

**4d. Using broom::augment() and geom_ribbon() in ggplot2, reproduce the above plot showing data, fit, fit interval, and prediction interval.**

```{r}

# create a sequence using the bite range/interval


new_data <- data.frame(dateOfBirth = seq(range(cadavers$dateOfBirth)[1],range(cadavers$dateOfBirth)[2], length.out= 50))


```
::: callout-tip
::: {#hello .greeting .message style="color: red;"}
Rember: Column name in the new data must be the same as the colname in cadavers object
:::
:::


```{r}
# augment data
cadavers_aug <- augment(cadavers_lm, newdata = new_data)


# Confidence interval
cadavers_ci <- predict(cadavers_lm,
                       newdata = cadavers_aug,
                       interval = "confidence")
head(cadavers_ci)


# prediction interval
cadavers_pi <- predict(cadavers_lm,
                          newdata = cadavers_aug,
                          interval = "prediction")


head(cadavers_pi)

```


```{r}

# Plot intervals

ggplot() +
  geom_point(data= cadavers, mapping = aes(x = dateOfBirth, y = deltaC14 )) +
  geom_smooth(data= cadavers, aes(dateOfBirth, y = deltaC14),
              method = "lm", se = FALSE, color = "darkblue") +
  geom_ribbon(data = cadavers_ci, aes(  x = cadavers_aug$dateOfBirth,
     ymin = lwr, ymax = upr),
    fill = "pink", alpha = 0.6) +
  geom_ribbon(data = cadavers_pi, aes(x = cadavers_aug$dateOfBirth,
    ymin = lwr, ymax = upr),
    fill = "grey", alpha = 0.3) 
  



```

